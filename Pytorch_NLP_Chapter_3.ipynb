{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch NLP Chapter 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjVM77qVXlHg"
      },
      "source": [
        "# **Glove**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZLUWr7rBLxc",
        "outputId": "606f363e-1fe2-4472-df83-425ea4a9c3f9"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-11 18:22:09--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-04-11 18:22:09--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-04-11 18:22:09--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.06MB/s    in 2m 40s  \n",
            "\n",
            "2021-04-11 18:24:49 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbzZlxJgBToN"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QNOXFZfDiMF",
        "outputId": "573cb342-a8db-404f-8b59-c239518ffde2"
      },
      "source": [
        "!unzip /content/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH_sVq4vCQCr"
      },
      "source": [
        "def loadGlove(path):\n",
        "  file = open(path, 'r')\n",
        "  model = {}\n",
        "  for l in file:\n",
        "    line = l.split()\n",
        "    word = line[0]\n",
        "    value = np.array([float(val) for val in line[1:]])\n",
        "    model[word] = value \n",
        "  return model\n",
        "\n",
        "glove = loadGlove('/content/glove.6B.50d.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0IPF_GlDbTg",
        "outputId": "a8e4e01e-fc00-4994-9449-b450d07d320d"
      },
      "source": [
        "glove['python']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.5897  , -0.55043 , -1.0106  ,  0.41226 ,  0.57348 ,  0.23464 ,\n",
              "       -0.35773 , -1.78    ,  0.10745 ,  0.74913 ,  0.45013 ,  1.0351  ,\n",
              "        0.48348 ,  0.47954 ,  0.51908 , -0.15053 ,  0.32474 ,  1.0789  ,\n",
              "       -0.90894 ,  0.42943 , -0.56388 ,  0.69961 ,  0.13501 ,  0.16557 ,\n",
              "       -0.063592,  0.35435 ,  0.42819 ,  0.1536  , -0.47018 , -1.0935  ,\n",
              "        1.361   , -0.80821 , -0.674   ,  1.2606  ,  0.29554 ,  1.0835  ,\n",
              "        0.2444  , -1.1877  , -0.60203 , -0.068315,  0.66256 ,  0.45336 ,\n",
              "       -1.0178  ,  0.68267 , -0.20788 , -0.73393 ,  1.2597  ,  0.15425 ,\n",
              "       -0.93256 , -0.15025 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-yrrM6gE8Zi",
        "outputId": "70f5e1c1-605b-43cb-f2e7-cf899b673c3a"
      },
      "source": [
        "cosine_similarity(glove['cat'].reshape(1, -1), glove['dog'].reshape(1, -1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.92180053]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT27pKpHFX7x",
        "outputId": "9531f887-8956-4156-9aa4-efcf318ea6ac"
      },
      "source": [
        "glove['python'].reshape(1, -1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.5897  , -0.55043 , -1.0106  ,  0.41226 ,  0.57348 ,  0.23464 ,\n",
              "        -0.35773 , -1.78    ,  0.10745 ,  0.74913 ,  0.45013 ,  1.0351  ,\n",
              "         0.48348 ,  0.47954 ,  0.51908 , -0.15053 ,  0.32474 ,  1.0789  ,\n",
              "        -0.90894 ,  0.42943 , -0.56388 ,  0.69961 ,  0.13501 ,  0.16557 ,\n",
              "        -0.063592,  0.35435 ,  0.42819 ,  0.1536  , -0.47018 , -1.0935  ,\n",
              "         1.361   , -0.80821 , -0.674   ,  1.2606  ,  0.29554 ,  1.0835  ,\n",
              "         0.2444  , -1.1877  , -0.60203 , -0.068315,  0.66256 ,  0.45336 ,\n",
              "        -1.0178  ,  0.68267 , -0.20788 , -0.73393 ,  1.2597  ,  0.15425 ,\n",
              "        -0.93256 , -0.15025 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QZMpMbjFfVx",
        "outputId": "e5f3b4c7-6105-439e-cad0-e4e2889412c0"
      },
      "source": [
        "cosine_similarity(glove['cat'].reshape(1, -1), glove['piano'].reshape(1, -1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19825255]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azb8IrKGGCD_",
        "outputId": "3d4f254b-7578-42ed-cd08-8971e9119684"
      },
      "source": [
        "predicted_king_embedding = glove['queen'] - glove['woman'] + glove['man']\n",
        "cosine_similarity(predicted_king_embedding.reshape(1, -1), glove['king'].reshape(1, -1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.85888392]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAOeJTycG4xu",
        "outputId": "68f3e722-299c-4a35-a3a9-05680d26def8"
      },
      "source": [
        "predicted_emphasis_embedding_1 = glove['softer'] - glove['soft']\n",
        "predicted_emphasis_embedding_2 = glove['darker'] - glove['dark']\n",
        "cosine_similarity(predicted_emphasis_embedding_1.reshape(1, -1), predicted_emphasis_embedding_2.reshape(1, -1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.52087747]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYHZBihJXpwv"
      },
      "source": [
        "# **CBOW**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW8GIw5yIMku"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To09XDtGX1eS"
      },
      "source": [
        "text = \"\"\"How that personage haunted my dreams, I need scarcely tell you. On\n",
        "stormy nights, when the wind shook the four corners of the house and\n",
        "the surf roared along the cove and up the cliffs, I would see him in a\n",
        "thousand forms, and with a thousand diabolical expressions. Now the leg\n",
        "would be cut off at the knee, now at the hip, now he was a monstrous\n",
        "kind of a creature who had never had but the one leg, and that in the\n",
        "middle of his body. To see him leap and run and pursue me over hedge and\n",
        "ditch was the worst of nightmares. And altogether I paid pretty dear for\n",
        "my monthly fourpenny piece, in the shape of these abominable fancies\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaGPwhr8YEo3"
      },
      "source": [
        "text = text.replace(',', '').replace('.', '').lower().split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwNvPImaYQh3",
        "outputId": "9c6caa13-dda3-4ee0-e637-5f0cbb5b37e8"
      },
      "source": [
        "corpus = set(text)\n",
        "corpus_length = len(corpus)\n",
        "\n",
        "word_dict = {}\n",
        "inverse_word_dict = {}\n",
        "\n",
        "for i, word in enumerate(corpus):\n",
        "  word_dict[word] = i\n",
        "  inverse_word_dict[i] = word \n",
        "\n",
        "\n",
        "data = []\n",
        "\n",
        "for i in range(2, len(text) - 2):\n",
        "  sentence = [text[i-2], text[i-1], text[i+1], text[i+2]]\n",
        "  target = text[i]\n",
        "  data.append((sentence, target))\n",
        "\n",
        "print(data[3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['haunted', 'my', 'i', 'need'], 'dreams')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99Al12aEZifP",
        "outputId": "038c6d90-731d-4abe-f04b-5fde444888ac"
      },
      "source": [
        "set(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'abominable',\n",
              " 'along',\n",
              " 'altogether',\n",
              " 'and',\n",
              " 'at',\n",
              " 'be',\n",
              " 'body',\n",
              " 'but',\n",
              " 'cliffs',\n",
              " 'corners',\n",
              " 'cove',\n",
              " 'creature',\n",
              " 'cut',\n",
              " 'dear',\n",
              " 'diabolical',\n",
              " 'ditch',\n",
              " 'dreams',\n",
              " 'expressions',\n",
              " 'fancies',\n",
              " 'for',\n",
              " 'forms',\n",
              " 'four',\n",
              " 'fourpenny',\n",
              " 'had',\n",
              " 'haunted',\n",
              " 'he',\n",
              " 'hedge',\n",
              " 'him',\n",
              " 'hip',\n",
              " 'his',\n",
              " 'house',\n",
              " 'how',\n",
              " 'i',\n",
              " 'in',\n",
              " 'kind',\n",
              " 'knee',\n",
              " 'leap',\n",
              " 'leg',\n",
              " 'me',\n",
              " 'middle',\n",
              " 'monstrous',\n",
              " 'monthly',\n",
              " 'my',\n",
              " 'need',\n",
              " 'never',\n",
              " 'nightmares',\n",
              " 'nights',\n",
              " 'now',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'one',\n",
              " 'over',\n",
              " 'paid',\n",
              " 'personage',\n",
              " 'piece',\n",
              " 'pretty',\n",
              " 'pursue',\n",
              " 'roared',\n",
              " 'run',\n",
              " 'scarcely',\n",
              " 'see',\n",
              " 'shape',\n",
              " 'shook',\n",
              " 'stormy',\n",
              " 'surf',\n",
              " 'tell',\n",
              " 'that',\n",
              " 'the',\n",
              " 'these',\n",
              " 'thousand',\n",
              " 'to',\n",
              " 'up',\n",
              " 'was',\n",
              " 'when',\n",
              " 'who',\n",
              " 'wind',\n",
              " 'with',\n",
              " 'worst',\n",
              " 'would',\n",
              " 'you'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDt27ZekZvu0"
      },
      "source": [
        "embedding_length = 20\n",
        "\n",
        "class CBOW(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, corpus_length, embedding_dim):\n",
        "    super(CBOW, self).__init__()\n",
        "\n",
        "    self.embeddings = nn.Embedding(corpus_length, embedding_dim)\n",
        "\n",
        "    self.linear1 = nn.Linear(embedding_dim, 64)\n",
        "    self.linear2 = nn.Linear(64, corpus_length)\n",
        "\n",
        "    self.activation_function1 = nn.ReLU()\n",
        "    self.activation_function2 = nn.LogSoftmax( dim = -1)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    embeds = sum(self.embeddings(inputs)).view(1, -1)\n",
        "    out = self.linear1(embeds)\n",
        "    out = self.activation_function1(out)\n",
        "    out = self.linear2(out)\n",
        "    out = self.activation_function2(out)\n",
        "    return out \n",
        "\n",
        "  def get_word_embeddings(self, word):\n",
        "    word = torch.LongTensor([word_dict[word]])\n",
        "    return self.embeddings(word).view(1, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swS0tCy0eFwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb6bcf84-be7b-4e4d-b22c-262e2ed1a7ad"
      },
      "source": [
        "model = CBOW(corpus_length, embedding_length)\n",
        "\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "def make_sentence_vector(sentence, word_dict):\n",
        "  idxs = [word_dict[w] for w in sentence]\n",
        "  return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "print(make_sentence_vector(['stormy', 'nights', 'when', 'the'], word_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([64, 58, 50, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsFEh0ZM2Ja9",
        "outputId": "24eb10fa-7047-4cd2-e605-19beb26801c1"
      },
      "source": [
        "for epoch in range(100):\n",
        "  epoch_loss = 0\n",
        "  for sentence, target in data:\n",
        "    model.zero_grad()\n",
        "    sentence_vector = make_sentence_vector(sentence, word_dict)\n",
        "    log_probs = model(sentence_vector)\n",
        "    loss = loss_function(log_probs, torch.tensor([word_dict[target]], dtype=torch.long))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss = epoch_loss + loss.data\n",
        "  print('Epoch: '+str(epoch)+', Loss: ' + str(epoch_loss.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 529.4207153320312\n",
            "Epoch: 1, Loss: 474.18426513671875\n",
            "Epoch: 2, Loss: 432.6933898925781\n",
            "Epoch: 3, Loss: 395.2223205566406\n",
            "Epoch: 4, Loss: 358.1815490722656\n",
            "Epoch: 5, Loss: 320.8206787109375\n",
            "Epoch: 6, Loss: 282.588134765625\n",
            "Epoch: 7, Loss: 243.8424835205078\n",
            "Epoch: 8, Loss: 205.9978485107422\n",
            "Epoch: 9, Loss: 170.1129150390625\n",
            "Epoch: 10, Loss: 137.52908325195312\n",
            "Epoch: 11, Loss: 109.46037292480469\n",
            "Epoch: 12, Loss: 86.3451156616211\n",
            "Epoch: 13, Loss: 68.09696197509766\n",
            "Epoch: 14, Loss: 54.076900482177734\n",
            "Epoch: 15, Loss: 43.386436462402344\n",
            "Epoch: 16, Loss: 35.392494201660156\n",
            "Epoch: 17, Loss: 29.198354721069336\n",
            "Epoch: 18, Loss: 24.522384643554688\n",
            "Epoch: 19, Loss: 20.869436264038086\n",
            "Epoch: 20, Loss: 18.005041122436523\n",
            "Epoch: 21, Loss: 15.754572868347168\n",
            "Epoch: 22, Loss: 13.970394134521484\n",
            "Epoch: 23, Loss: 12.510107040405273\n",
            "Epoch: 24, Loss: 11.320457458496094\n",
            "Epoch: 25, Loss: 10.314642906188965\n",
            "Epoch: 26, Loss: 9.460220336914062\n",
            "Epoch: 27, Loss: 8.731156349182129\n",
            "Epoch: 28, Loss: 8.09771728515625\n",
            "Epoch: 29, Loss: 7.546098232269287\n",
            "Epoch: 30, Loss: 7.059195041656494\n",
            "Epoch: 31, Loss: 6.626194000244141\n",
            "Epoch: 32, Loss: 6.242023468017578\n",
            "Epoch: 33, Loss: 5.898077011108398\n",
            "Epoch: 34, Loss: 5.585137367248535\n",
            "Epoch: 35, Loss: 5.303779602050781\n",
            "Epoch: 36, Loss: 5.046968936920166\n",
            "Epoch: 37, Loss: 4.811713218688965\n",
            "Epoch: 38, Loss: 4.596376419067383\n",
            "Epoch: 39, Loss: 4.400480270385742\n",
            "Epoch: 40, Loss: 4.21559476852417\n",
            "Epoch: 41, Loss: 4.0484161376953125\n",
            "Epoch: 42, Loss: 3.892029047012329\n",
            "Epoch: 43, Loss: 3.7455594539642334\n",
            "Epoch: 44, Loss: 3.6102871894836426\n",
            "Epoch: 45, Loss: 3.4833133220672607\n",
            "Epoch: 46, Loss: 3.3648855686187744\n",
            "Epoch: 47, Loss: 3.253230094909668\n",
            "Epoch: 48, Loss: 3.1488380432128906\n",
            "Epoch: 49, Loss: 3.0496957302093506\n",
            "Epoch: 50, Loss: 2.9569945335388184\n",
            "Epoch: 51, Loss: 2.869293451309204\n",
            "Epoch: 52, Loss: 2.7860069274902344\n",
            "Epoch: 53, Loss: 2.7074368000030518\n",
            "Epoch: 54, Loss: 2.632826566696167\n",
            "Epoch: 55, Loss: 2.561638355255127\n",
            "Epoch: 56, Loss: 2.4948573112487793\n",
            "Epoch: 57, Loss: 2.4304490089416504\n",
            "Epoch: 58, Loss: 2.369260787963867\n",
            "Epoch: 59, Loss: 2.31101393699646\n",
            "Epoch: 60, Loss: 2.255328416824341\n",
            "Epoch: 61, Loss: 2.201883554458618\n",
            "Epoch: 62, Loss: 2.1512436866760254\n",
            "Epoch: 63, Loss: 2.102263927459717\n",
            "Epoch: 64, Loss: 2.0557539463043213\n",
            "Epoch: 65, Loss: 2.0107452869415283\n",
            "Epoch: 66, Loss: 1.9675953388214111\n",
            "Epoch: 67, Loss: 1.9264556169509888\n",
            "Epoch: 68, Loss: 1.8866342306137085\n",
            "Epoch: 69, Loss: 1.8484218120574951\n",
            "Epoch: 70, Loss: 1.8114478588104248\n",
            "Epoch: 71, Loss: 1.7761441469192505\n",
            "Epoch: 72, Loss: 1.7417628765106201\n",
            "Epoch: 73, Loss: 1.7090590000152588\n",
            "Epoch: 74, Loss: 1.6770422458648682\n",
            "Epoch: 75, Loss: 1.6462258100509644\n",
            "Epoch: 76, Loss: 1.6165882349014282\n",
            "Epoch: 77, Loss: 1.5879971981048584\n",
            "Epoch: 78, Loss: 1.560086727142334\n",
            "Epoch: 79, Loss: 1.5332167148590088\n",
            "Epoch: 80, Loss: 1.5071760416030884\n",
            "Epoch: 81, Loss: 1.4818476438522339\n",
            "Epoch: 82, Loss: 1.4575320482254028\n",
            "Epoch: 83, Loss: 1.433899998664856\n",
            "Epoch: 84, Loss: 1.4107547998428345\n",
            "Epoch: 85, Loss: 1.3885728120803833\n",
            "Epoch: 86, Loss: 1.3669209480285645\n",
            "Epoch: 87, Loss: 1.345772385597229\n",
            "Epoch: 88, Loss: 1.3255151510238647\n",
            "Epoch: 89, Loss: 1.3055646419525146\n",
            "Epoch: 90, Loss: 1.286266803741455\n",
            "Epoch: 91, Loss: 1.2674782276153564\n",
            "Epoch: 92, Loss: 1.24923837184906\n",
            "Epoch: 93, Loss: 1.231438159942627\n",
            "Epoch: 94, Loss: 1.2141523361206055\n",
            "Epoch: 95, Loss: 1.1972640752792358\n",
            "Epoch: 96, Loss: 1.180888056755066\n",
            "Epoch: 97, Loss: 1.1647453308105469\n",
            "Epoch: 98, Loss: 1.1492271423339844\n",
            "Epoch: 99, Loss: 1.1340382099151611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rzuOaYG3dVZ"
      },
      "source": [
        "def get_predicted_result(input, inverse_word_dict):\n",
        "  index = np.argmax(input)\n",
        "  return inverse_word_dict[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1-miSki4o5n"
      },
      "source": [
        "def predict_sentence(sentence):\n",
        "  sentence_split = sentence.replace('.', '').lower().split()\n",
        "  sentence_vector = make_sentence_vector(sentence_split, word_dict)\n",
        "  prediction_array = model(sentence_vector).data.numpy()\n",
        "  print('Preceding Words: {}\\n'.format(sentence_split[:2]))\n",
        "  print('Predicted Word: {}\\n'.format(get_predicted_result(prediction_array[0], inverse_word_dict)))\n",
        "  print('Following Words: {}\\n'.format(sentence_split[2:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I75v0ALf5sqH",
        "outputId": "1172cb6a-ffb1-4e0f-c4be-9f7ec9934c12"
      },
      "source": [
        "predict_sentence('to see leap and')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preceding Words: ['to', 'see']\n",
            "\n",
            "Predicted Word: him\n",
            "\n",
            "Following Words: ['leap', 'and']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO_InYHY5yr0",
        "outputId": "9cba0d1e-a21d-49a7-c516-e74019455b5e"
      },
      "source": [
        "print(model.get_word_embeddings('leap'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.1024,  1.0129, -2.1892, -0.3026,  0.3400, -1.9102,  0.0484, -0.8698,\n",
            "          0.3539, -0.6314, -0.2415,  0.8329,  0.0054, -0.1078, -0.5404,  0.5172,\n",
            "          0.7934,  0.5753, -0.2397, -1.9517]], grad_fn=<ViewBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9TB_qH1QfXZ"
      },
      "source": [
        "# **Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PesYjX3uRHiG",
        "outputId": "d8df7741-6846-4a33-ed88-8e084142a681"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjnQwWue5-uC"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bps4d2eQQveL",
        "outputId": "8d0397ef-f2ea-4a6b-9865-f17ea488a756"
      },
      "source": [
        "text = 'This is a single sentence.'\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'is', 'a', 'single', 'sentence', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmpIqWMLQ94o",
        "outputId": "544b084b-172c-4319-90e4-a08279b24638"
      },
      "source": [
        "no_punctuation = [word.lower() for word in tokens if word.isalpha()]\n",
        "print(no_punctuation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['this', 'is', 'a', 'single', 'sentence']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h2mrz2IRd3X",
        "outputId": "20421bd0-97a7-4ef9-93d3-00f271f807f6"
      },
      "source": [
        "text = \"This is the first sentence. This is the second sentence. A document contains many sentences.\"\n",
        "print(sent_tokenize(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This is the first sentence.', 'This is the second sentence.', 'A document contains many sentences.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE6Ux7ssSJom",
        "outputId": "72a96e27-3a72-477a-d134-a1460720218e"
      },
      "source": [
        "print([word_tokenize(sentence) for sentence in sent_tokenize(text)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['This', 'is', 'the', 'first', 'sentence', '.'], ['This', 'is', 'the', 'second', 'sentence', '.'], ['A', 'document', 'contains', 'many', 'sentences', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e--Opg-UTMYJ",
        "outputId": "2faacdd3-1bf5-4bbe-a33b-7fa29a03dee7"
      },
      "source": [
        "nltk.download(\"stopwords\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPL8iOXzSu71",
        "outputId": "548078b1-8295-44e0-bfcc-858d78566001"
      },
      "source": [
        "stop_words = stopwords.words('english')\n",
        "print(stop_words[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQuW9UtHS-RV",
        "outputId": "a7019457-ae43-4dbe-a98f-0ca2c2f87f49"
      },
      "source": [
        "text = 'This is a single sentence.'\n",
        "tokens = [token for token in word_tokenize(text) if token not in stop_words]\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'single', 'sentence', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajUayBtOUh8b"
      },
      "source": [
        "# **POS Tagging and Chunking**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ejNvK9LUg27",
        "outputId": "8e474537-7995-45bd-dd4f-5dc84e6f54a8"
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('tagsets')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWn9MDo5TvDj",
        "outputId": "685179e2-ef32-429b-97e4-fb6c9627a6ab"
      },
      "source": [
        "sentence = 'The big dog is sleeping on the bed'\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "nltk.pos_tag(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DT'),\n",
              " ('big', 'JJ'),\n",
              " ('dog', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('sleeping', 'VBG'),\n",
              " ('on', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('bed', 'NN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdJHwFX5V_Wg",
        "outputId": "0c00c237-33d3-4bc5-9da9-4a321ddc1a57"
      },
      "source": [
        "nltk.help.upenn_tagset(\"VBG\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VBG: verb, present participle or gerund\n",
            "    telegraphing stirring focusing angering judging stalling lactating\n",
            "    hankerin' alleging veering capping approaching traveling besieging\n",
            "    encrypting interrupting erasing wincing ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYKD6YosWOZP"
      },
      "source": [
        "tagged = nltk.pos_tag(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax0agC6OWoct",
        "outputId": "be6f2d2e-4065-455a-ec08-bdf1c4847be1"
      },
      "source": [
        "tagged"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DT'),\n",
              " ('big', 'JJ'),\n",
              " ('dog', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('sleeping', 'VBG'),\n",
              " ('on', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('bed', 'NN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LC5k0epWwtB"
      },
      "source": [
        "expression = ('NP: {<DT>?<JJ>*<NN>}')\n",
        "REchunkParser = nltk.RegexpParser(expression)\n",
        "tree = REchunkParser.parse(tagged)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OXY0IVFXseM",
        "outputId": "3d2804a6-e262-4e3e-8c23-3b5ae60678c1"
      },
      "source": [
        "print(tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  (NP The/DT big/JJ dog/NN)\n",
            "  is/VBZ\n",
            "  sleeping/VBG\n",
            "  on/IN\n",
            "  (NP the/DT bed/NN))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0J7kaNRdPYp"
      },
      "source": [
        "# **TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6mVQi62XvB8"
      },
      "source": [
        "import nltk \n",
        "from nltk.tokenize import sent_tokenize, word_tokenize \n",
        "from nltk.corpus import stopwords \n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIDPahuRfZvx",
        "outputId": "bb4a2b70-305e-407f-a46d-8531c5fb6030"
      },
      "source": [
        "nltk.download('gutenberg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI0dDHv7-vGF",
        "outputId": "b3c6da23-5ac3-46bf-a39c-b4d95c432626"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upKJ5UqIdq-y"
      },
      "source": [
        "emma = nltk.corpus.gutenberg.sents('austen-emma.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZElurYqqfP3B"
      },
      "source": [
        "emma_sentences = []\n",
        "emma_word_set = []\n",
        "\n",
        "for sentence in emma:\n",
        "  emma_sentences.append([word.lower() for word in sentence if word.isalpha()])\n",
        "  for word in sentence:\n",
        "    if word.isalpha():\n",
        "      emma_word_set.append(word.lower())\n",
        "\n",
        "emma_word_set = set(emma_word_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnZFqlz8-ruc",
        "outputId": "60c945e2-9eec-4ad9-8b1b-e0149fa562a0"
      },
      "source": [
        "def TermFreq(document, word):\n",
        "  doc_length = len(document)\n",
        "  occurances = len([w for w in document if w == word])\n",
        "  return occurances / doc_length\n",
        "\n",
        "\n",
        "TermFreq(emma_sentences[5], 'ago')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.024390243902439025"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHJGCwh_BREu"
      },
      "source": [
        "def build_DF_dict():\n",
        "  output = {}\n",
        "  for word in emma_word_set:\n",
        "    output[word] = 0\n",
        "    for doc in emma_sentences:\n",
        "      if word in doc:\n",
        "        output[word] = output[word] + 1\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXWzofXtCF4U",
        "outputId": "e2acefc4-b6d3-4f40-b57a-a6d52bc7458d"
      },
      "source": [
        "df_dict = build_DF_dict()\n",
        "df_dict['ago']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci2Y9GilCS6B"
      },
      "source": [
        "def InverseDocumentFrequency(word):\n",
        "  N = len(emma_sentences)\n",
        "  try:\n",
        "    df = df_dict[word] + 1\n",
        "  except:\n",
        "    df = 1\n",
        "  return np.log(N/df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtHYbXxjEvha",
        "outputId": "977ffec9-afd5-4a8e-86da-984ecd566405"
      },
      "source": [
        "InverseDocumentFrequency('ago')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.459198592104122"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8WywlIrE1a9"
      },
      "source": [
        "def TFIDF(doc, word):\n",
        "  tf = TermFreq(doc, word)\n",
        "  idf = InverseDocumentFrequency(word)\n",
        "  return tf * idf \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FqcXBikH3S6",
        "outputId": "fd4622dc-379e-4ccb-ed69-8cb4d802d321"
      },
      "source": [
        "print('ago - ' + str(TFIDF(emma_sentences[5], 'ago')))\n",
        "print('indistinct - ' + str(TFIDF(emma_sentences[5], 'indistinct')))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ago - 0.13315118517327126\n",
            "indistinct - 0.20152582861001603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0YnPq77IY9W"
      },
      "source": [
        "def loadGlove(path):\n",
        "  file = open(path, 'r')\n",
        "  model = {}\n",
        "  for l in file:\n",
        "    line = l.split()\n",
        "    word = line[0]\n",
        "    value = np.array([float(val) for val in line[1:]])\n",
        "    model[word] = value\n",
        "  return model \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjn1-OmiKPX_"
      },
      "source": [
        "glove = loadGlove('glove.6B.50d.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J70shMMgMSzm",
        "outputId": "a3ce3da3-e8d0-4534-92cc-dd48cad006d1"
      },
      "source": [
        "embeddings = []\n",
        "\n",
        "for word in emma_sentences[5]:\n",
        "  embeddings.append(glove[word])\n",
        "\n",
        "mean_embedding = np.mean(embeddings, axis=0).reshape(1, -1)\n",
        "print(mean_embedding)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3.32575634e-01  3.16596488e-01 -1.80050732e-01 -3.82070951e-01\n",
            "   4.98493527e-01  5.33804805e-01 -5.46517073e-01  9.12476195e-02\n",
            "  -1.31538483e-01 -2.71967805e-02  2.99867317e-02  2.64278024e-02\n",
            "  -2.06519756e-01 -1.54796634e-01  4.28036366e-01 -5.74977317e-02\n",
            "  -2.65928778e-01  1.60373902e-02 -2.84913561e-01 -2.01252268e-01\n",
            "  -5.96390732e-02  5.72458220e-01  2.06195927e-01 -1.54312293e-01\n",
            "   2.52049805e-01 -1.64638200e+00 -3.42686049e-01  1.02592522e-01\n",
            "   1.42848000e-01 -1.09779902e-01  2.89345488e+00  7.36985634e-02\n",
            "  -3.73648780e-03 -2.76292784e-01  1.50580049e-01  9.80399951e-02\n",
            "   2.24408780e-03  2.83664024e-01  3.92979024e-02 -2.98091634e-01\n",
            "  -1.17309171e-01  2.08815776e-01  6.89953902e-03  2.92777244e-02\n",
            "   5.54180122e-02 -2.20519707e-01 -2.82007805e-01 -4.34917439e-01\n",
            "  -9.69051537e-02 -1.67569878e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TilbwAKWMro_",
        "outputId": "d1dd1b0b-1202-435a-f419-95db9a5e3a7f"
      },
      "source": [
        "embeddings = []\n",
        "\n",
        "for word in emma_sentences[5]:\n",
        "  tfidf = TFIDF(emma_sentences[5], word)\n",
        "  embeddings.append(glove[word] * tfidf)\n",
        "\n",
        "tfidf_weighted_embedding = np.mean(embeddings, axis=0).reshape(1, -1)\n",
        "print(tfidf_weighted_embedding)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.03390627  0.04567951 -0.02513047 -0.05553374  0.06523389  0.07031937\n",
            "  -0.06309126  0.02674499 -0.01073998 -0.00509068  0.00518551  0.00818713\n",
            "  -0.01610237 -0.01486281  0.04954961 -0.0107796  -0.05029558  0.00039276\n",
            "  -0.0192399  -0.01344365 -0.01123742  0.08506534  0.02145731 -0.0159164\n",
            "   0.04411737 -0.17889813 -0.04006272  0.01603446  0.02090289 -0.01344211\n",
            "   0.28346797  0.00696015  0.00484046 -0.02637939  0.01537125  0.01611019\n",
            "   0.00316879  0.0324516   0.00829024 -0.04200008 -0.0058922   0.01996137\n",
            "  -0.00305491 -0.00355021  0.01175475 -0.03423196 -0.02943769 -0.06810232\n",
            "  -0.00775695 -0.0181068 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqzKiSRWNauN",
        "outputId": "9ebfcdac-167e-4cec-9c50-154ccff76883"
      },
      "source": [
        "cosine_similarity(mean_embedding, tfidf_weighted_embedding)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.98653879]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8rfbKwDOKZb"
      },
      "source": [
        "emma_set = set([\"I\",\"am\", \"a\", \"man\", \"and\", \"you\", \"was\", \"a\", \"man\", \"though\" ])\n",
        "sentences = [[\"I\",\"am\", \"a\", \"man\", \"and\", \"a\", \"man\"], [\"you\", \"was\", \"a\", \"man\", \"though\"]]\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV3tkg8NP8Pi",
        "outputId": "3aeda740-6297-4fad-e455-f4481b972998"
      },
      "source": [
        "output = {}\n",
        "\n",
        "for word in emma_set:\n",
        "  output[word] = 0\n",
        "  for doc in sentences:\n",
        "    if word in doc:\n",
        "      output[word] = output[word] + 1\n",
        "\n",
        "\n",
        "print(output)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'was': 1, 'I': 1, 'man': 2, 'am': 1, 'you': 1, 'though': 1, 'and': 1, 'a': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39yqWw53Qi9O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}