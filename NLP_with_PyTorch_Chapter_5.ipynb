{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP with PyTorch Chapter 5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTIYBz0cwtoF",
        "outputId": "50f89d79-b1ff-46ac-aaa1-1b28183f2534"
      },
      "source": [
        "!pip install torch==1.0.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/3b/0b8de6e654c2983898564226792c6f09d9bcaba97b7b29c40e4ed4ae43ed/torch-1.0.0-cp37-cp37m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K     |████████████████████████████████| 591.8MB 30kB/s \n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "Successfully installed torch-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsTNTBIDxTQE",
        "outputId": "fd04a932-9be0-447d-81e7-574307d20e1e"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e_1IlSBjlfK"
      },
      "source": [
        "import pandas as pd\n",
        "from string import punctuation\n",
        "import numpy as np\n",
        "import torch \n",
        "from nltk.tokenize import word_tokenize \n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import json"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqvMVCWkkjYS"
      },
      "source": [
        "with open(\"sentiment.txt\") as f:\n",
        "  reviews = f.read()\n",
        "\n",
        "data = pd.DataFrame([review.split('\\t') for review in reviews.split('\\n')])\n",
        "\n",
        "data.columns = ['Review', 'Sentiment']\n",
        "\n",
        "data = data.sample(frac=1)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "mJN_ML6Hnh3s",
        "outputId": "9be78f33-c278-455c-c640-9424c41d7dba"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2771</th>\n",
              "      <td>VERY cheap plastic, creaks like an old wooden ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>The flat reenactments don't hold your attentio...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1422</th>\n",
              "      <td>Furthermore, you can't even find hours of oper...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>This short film certainly pulls no punches.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2487</th>\n",
              "      <td>Unfortunately the ability to actually know you...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Review Sentiment\n",
              "2771  VERY cheap plastic, creaks like an old wooden ...         0\n",
              "224   The flat reenactments don't hold your attentio...         0\n",
              "1422  Furthermore, you can't even find hours of oper...         0\n",
              "25        This short film certainly pulls no punches.           0\n",
              "2487  Unfortunately the ability to actually know you...         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoIHSoakvxrD",
        "outputId": "3ebe4d87-b50a-4e16-d1d5-ce216d3c31f5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LNihAx_nrBK"
      },
      "source": [
        "def split_words_reviews(data):\n",
        "  text = list(data['Review'].values)\n",
        "  clean_text = []\n",
        "  for t in text:\n",
        "    clean_text.append(t.translate(str.maketrans('', '', punctuation)).lower().rstrip())\n",
        "  tokenized = [word_tokenize(x) for x in clean_text]\n",
        "  all_text = []\n",
        "  for tokens in tokenized:\n",
        "    for t in tokens:\n",
        "      all_text.append(t)\n",
        "  return tokenized, set(all_text)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aojgreyvMKL"
      },
      "source": [
        "reviews, vocab = split_words_reviews(data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv63bhyEvk_s",
        "outputId": "4a2b9269-acfb-4c3a-e531-121aece3809e"
      },
      "source": [
        "reviews[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['very', 'cheap', 'plastic', 'creaks', 'like', 'an', 'old', 'wooden', 'floor']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojcLnVnfv_Eb"
      },
      "source": [
        "def create_dictionaries(words):\n",
        "  word_to_int_dict = {w:i+1 for i, w in enumerate(words)}\n",
        "  in_to_word_dict = {i:w for w, i in word_to_int_dict.items()}\n",
        "  return word_to_int_dict, in_to_word_dict"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTQvxiYeUKyv"
      },
      "source": [
        "word_to_int_dict, int_to_word_dict = create_dictionaries(vocab)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7Pgc8ISUWpS",
        "outputId": "e22458c9-ce3f-4bdd-b631-3b6e01554a87"
      },
      "source": [
        "int_to_word_dict"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'spinach',\n",
              " 2: 'open',\n",
              " 3: 'kidnapped',\n",
              " 4: 'largely',\n",
              " 5: 'exceeding',\n",
              " 6: 'funnyall',\n",
              " 7: 'plays',\n",
              " 8: 'message',\n",
              " 9: 'install',\n",
              " 10: 'rickman',\n",
              " 11: 'violinists',\n",
              " 12: 'customize',\n",
              " 13: 'complaint',\n",
              " 14: 'remorse',\n",
              " 15: 'lock',\n",
              " 16: '95',\n",
              " 17: 'overhip',\n",
              " 18: 'eyepleasing',\n",
              " 19: 'crocdodile',\n",
              " 20: 'shame',\n",
              " 21: 'professionals',\n",
              " 22: 'disgraceful',\n",
              " 23: 'owed',\n",
              " 24: 'impossible',\n",
              " 25: 'famed',\n",
              " 26: 'dualpurpose',\n",
              " 27: 'hot',\n",
              " 28: 'florida',\n",
              " 29: 'extremely',\n",
              " 30: 'expanded',\n",
              " 31: 'dusted',\n",
              " 32: 'copier',\n",
              " 33: 'four',\n",
              " 34: 'hbo',\n",
              " 35: 'recessed',\n",
              " 36: 'vinaigrette',\n",
              " 37: '350',\n",
              " 38: 'tract',\n",
              " 39: 'future',\n",
              " 40: 'jealousy',\n",
              " 41: 'killing',\n",
              " 42: 'wildly',\n",
              " 43: 'tired',\n",
              " 44: 'endearing',\n",
              " 45: 'beensteppedinandtrackedeverywhere',\n",
              " 46: 'technology',\n",
              " 47: 'stars',\n",
              " 48: 'peculiarity',\n",
              " 49: 'wake',\n",
              " 50: 'advertised',\n",
              " 51: 'shoots',\n",
              " 52: 'survived',\n",
              " 53: 'enthusiastic',\n",
              " 54: 'still',\n",
              " 55: 'shipped',\n",
              " 56: 'minor',\n",
              " 57: 'little',\n",
              " 58: 'looking',\n",
              " 59: 'masterpieces',\n",
              " 60: 'reasonable',\n",
              " 61: 'burger',\n",
              " 62: 'palmtopcameracellphone',\n",
              " 63: 'gave',\n",
              " 64: 'tries',\n",
              " 65: 'terms',\n",
              " 66: 'unwelcome',\n",
              " 67: 'era',\n",
              " 68: 'thoughtprovoking',\n",
              " 69: '2mp',\n",
              " 70: 'forgetting',\n",
              " 71: 'thereplacement',\n",
              " 72: 'soyo',\n",
              " 73: 'right',\n",
              " 74: 'charismatic',\n",
              " 75: 'bland',\n",
              " 76: 'wondered',\n",
              " 77: 'balance',\n",
              " 78: 'northern',\n",
              " 79: 'aimless',\n",
              " 80: 'home',\n",
              " 81: 'off',\n",
              " 82: 'sit',\n",
              " 83: 'wholesome',\n",
              " 84: 'beautiful',\n",
              " 85: 'z',\n",
              " 86: 'heist',\n",
              " 87: 'retreat',\n",
              " 88: 'saving',\n",
              " 89: 'coppolas',\n",
              " 90: 'noodles',\n",
              " 91: 'bartenders',\n",
              " 92: 'claimed',\n",
              " 93: 'idiot',\n",
              " 94: 'realised',\n",
              " 95: 'idiotsavant',\n",
              " 96: 'cotta',\n",
              " 97: 'cotton',\n",
              " 98: 'show',\n",
              " 99: 'lord',\n",
              " 100: 'fest',\n",
              " 101: 'contrived',\n",
              " 102: 'blame',\n",
              " 103: 'tranquillity',\n",
              " 104: 'potentially',\n",
              " 105: 'light',\n",
              " 106: 'yay',\n",
              " 107: 'gas',\n",
              " 108: 'microphone',\n",
              " 109: 'bitchy',\n",
              " 110: 'insult',\n",
              " 111: 'continuity',\n",
              " 112: 'joint',\n",
              " 113: 'waterproof',\n",
              " 114: 'batteries',\n",
              " 115: 'beauty',\n",
              " 116: 'sounded',\n",
              " 117: 'function',\n",
              " 118: 'monolog',\n",
              " 119: 'wiping',\n",
              " 120: 'purchasing',\n",
              " 121: 'speakerphone',\n",
              " 122: 'predictably',\n",
              " 123: 'fell',\n",
              " 124: 'barking',\n",
              " 125: 'cavier',\n",
              " 126: 'connerys',\n",
              " 127: '40min',\n",
              " 128: 'downright',\n",
              " 129: 'excellently',\n",
              " 130: 'iphone',\n",
              " 131: 'cowardice',\n",
              " 132: 'caesar',\n",
              " 133: 'insulin',\n",
              " 134: 'hilt',\n",
              " 135: 'nicest',\n",
              " 136: 'lid',\n",
              " 137: 'spy',\n",
              " 138: 'single',\n",
              " 139: 'dish',\n",
              " 140: 'sink',\n",
              " 141: 'memorized',\n",
              " 142: 'survivors',\n",
              " 143: 'creamy',\n",
              " 144: 'relocated',\n",
              " 145: 'flavored',\n",
              " 146: 'stuart',\n",
              " 147: 'humans',\n",
              " 148: 'gay',\n",
              " 149: 'mom',\n",
              " 150: 'teaches',\n",
              " 151: 'amount',\n",
              " 152: 'africa',\n",
              " 153: 'treatments',\n",
              " 154: 'bartender',\n",
              " 155: 'among',\n",
              " 156: 'explains',\n",
              " 157: 'superb',\n",
              " 158: 'fellow',\n",
              " 159: 'interpretations',\n",
              " 160: 'blush',\n",
              " 161: 'natural',\n",
              " 162: 'sensibility',\n",
              " 163: 'operation',\n",
              " 164: 'wine',\n",
              " 165: 'terrific',\n",
              " 166: 'servers',\n",
              " 167: 'tried',\n",
              " 168: 'compromise',\n",
              " 169: 'herewhat',\n",
              " 170: 'concerns',\n",
              " 171: 'central',\n",
              " 172: 'bill',\n",
              " 173: 'mall',\n",
              " 174: 'muffled',\n",
              " 175: 'come',\n",
              " 176: 'dripping',\n",
              " 177: 'falls',\n",
              " 178: 'circumstances',\n",
              " 179: 'legit',\n",
              " 180: 'ue',\n",
              " 181: 'serving',\n",
              " 182: 'almost',\n",
              " 183: 'dna',\n",
              " 184: 'film',\n",
              " 185: 'photography',\n",
              " 186: 'revealing',\n",
              " 187: 'itll',\n",
              " 188: 'errors',\n",
              " 189: 'elias',\n",
              " 190: 'next',\n",
              " 191: 'run',\n",
              " 192: 'limitations',\n",
              " 193: 'watered',\n",
              " 194: 'juicehighy',\n",
              " 195: 'disparate',\n",
              " 196: 'cuisine',\n",
              " 197: 'idealogical',\n",
              " 198: 'oscar',\n",
              " 199: 'mchattie',\n",
              " 200: 'finally',\n",
              " 201: 'but',\n",
              " 202: 'pleasantly',\n",
              " 203: 'memories',\n",
              " 204: 'result',\n",
              " 205: 'schultz',\n",
              " 206: 'menu',\n",
              " 207: 'hold',\n",
              " 208: 'sprouts',\n",
              " 209: 'allowing',\n",
              " 210: 'protected',\n",
              " 211: 'ones',\n",
              " 212: 'uniqueness',\n",
              " 213: 'warm',\n",
              " 214: 'unreliable',\n",
              " 215: 'trippy',\n",
              " 216: 'reviews',\n",
              " 217: 'is',\n",
              " 218: 'pledge',\n",
              " 219: 'wily',\n",
              " 220: '34ths',\n",
              " 221: 'trinity',\n",
              " 222: 'repeats',\n",
              " 223: 'pho',\n",
              " 224: 'yawn',\n",
              " 225: 'phonethe',\n",
              " 226: 'radiant',\n",
              " 227: 'connection',\n",
              " 228: 'earphones',\n",
              " 229: 'losing',\n",
              " 230: 'purcashed',\n",
              " 231: 'distorted',\n",
              " 232: 'forever',\n",
              " 233: 'workers',\n",
              " 234: 'head',\n",
              " 235: 'day',\n",
              " 236: 'subjects',\n",
              " 237: 'comprehensible',\n",
              " 238: 'directly',\n",
              " 239: '6',\n",
              " 240: 'left',\n",
              " 241: 'suggest',\n",
              " 242: 'crayonpencil',\n",
              " 243: 'thinking',\n",
              " 244: 'crazy',\n",
              " 245: 'literally',\n",
              " 246: 'antithesis',\n",
              " 247: 'keith',\n",
              " 248: 'oldfashioned',\n",
              " 249: 'lightly',\n",
              " 250: 'lunch',\n",
              " 251: 'provide',\n",
              " 252: 'nevertheless',\n",
              " 253: 'haul',\n",
              " 254: 'refund',\n",
              " 255: 'amazingly',\n",
              " 256: 'form',\n",
              " 257: 'misleading',\n",
              " 258: 'cheerless',\n",
              " 259: 'wanted',\n",
              " 260: 'history',\n",
              " 261: 'how',\n",
              " 262: 'imagination',\n",
              " 263: 'less',\n",
              " 264: 'opinion',\n",
              " 265: 'shipment',\n",
              " 266: 'mean',\n",
              " 267: 'unsatisfactory',\n",
              " 268: 'tonight',\n",
              " 269: 'subtitles',\n",
              " 270: 'crowdpleaserthis',\n",
              " 271: 'edible',\n",
              " 272: 'appealing',\n",
              " 273: 'gifted',\n",
              " 274: 'sugary',\n",
              " 275: 'letting',\n",
              " 276: 'originally',\n",
              " 277: 'onlyi',\n",
              " 278: 'deffinitely',\n",
              " 279: 'nuts',\n",
              " 280: 'bbq',\n",
              " 281: 'wifes',\n",
              " 282: 'villain',\n",
              " 283: 'thread',\n",
              " 284: 'along',\n",
              " 285: 'proclaimed',\n",
              " 286: '25',\n",
              " 287: 'charging',\n",
              " 288: 'securely',\n",
              " 289: 'soft',\n",
              " 290: 'mishima',\n",
              " 291: 'sandra',\n",
              " 292: 'respect',\n",
              " 293: 'childlike',\n",
              " 294: 'scenery',\n",
              " 295: 'crowds',\n",
              " 296: 'hadnt',\n",
              " 297: 'sole',\n",
              " 298: 'those',\n",
              " 299: 'specs',\n",
              " 300: '17',\n",
              " 301: 'ballet',\n",
              " 302: 'horrendously',\n",
              " 303: 'will',\n",
              " 304: 'ri',\n",
              " 305: 'celluloid',\n",
              " 306: 'characterage',\n",
              " 307: 'renders',\n",
              " 308: 'magazine',\n",
              " 309: 'should',\n",
              " 310: 'guess',\n",
              " 311: 'heche',\n",
              " 312: 'must',\n",
              " 313: 'muststop',\n",
              " 314: 'keypads',\n",
              " 315: 'cashew',\n",
              " 316: 'sexobsessed',\n",
              " 317: 'strong',\n",
              " 318: 'anything',\n",
              " 319: 'flashbacks',\n",
              " 320: 'stay',\n",
              " 321: 'relate',\n",
              " 322: 'warnings',\n",
              " 323: 'aesthetically',\n",
              " 324: 'stable',\n",
              " 325: 'brother',\n",
              " 326: 'intelligent',\n",
              " 327: 'brutal',\n",
              " 328: 'allstar',\n",
              " 329: 'at',\n",
              " 330: 'real',\n",
              " 331: 'south',\n",
              " 332: 'frequently4',\n",
              " 333: 'crisp',\n",
              " 334: 'serves',\n",
              " 335: 'stick',\n",
              " 336: 'screenthis',\n",
              " 337: 'toons',\n",
              " 338: 'atmosphere',\n",
              " 339: 'noble',\n",
              " 340: 'childrens',\n",
              " 341: 'megapixels',\n",
              " 342: 'quick',\n",
              " 343: 'volume',\n",
              " 344: '9',\n",
              " 345: '7',\n",
              " 346: 'rolled',\n",
              " 347: 'bring',\n",
              " 348: 'secondly',\n",
              " 349: 'melted',\n",
              " 350: 'burtons',\n",
              " 351: 'phoenix',\n",
              " 352: 'screens',\n",
              " 353: 'machine',\n",
              " 354: 'workingeating',\n",
              " 355: 'kris',\n",
              " 356: 'highlighted',\n",
              " 357: 'elaborately',\n",
              " 358: 'moods',\n",
              " 359: 'delicioso',\n",
              " 360: 'deliciously',\n",
              " 361: 'logic',\n",
              " 362: 'noir',\n",
              " 363: 'connected',\n",
              " 364: 'underwater',\n",
              " 365: 'howe',\n",
              " 366: 'biscuit',\n",
              " 367: 'kudos',\n",
              " 368: 'handsfree',\n",
              " 369: 'jutland',\n",
              " 370: 'appearance',\n",
              " 371: 'charlie',\n",
              " 372: 'awards',\n",
              " 373: 'apt',\n",
              " 374: 'longwearing',\n",
              " 375: 'move',\n",
              " 376: '23',\n",
              " 377: 'indication',\n",
              " 378: 'indoors',\n",
              " 379: 'muppets',\n",
              " 380: 'exactly',\n",
              " 381: 'uploaded',\n",
              " 382: 'taken',\n",
              " 383: 'every',\n",
              " 384: 'deserves',\n",
              " 385: 'pretentious',\n",
              " 386: 'youdo',\n",
              " 387: 'inviting',\n",
              " 388: 'magnificent',\n",
              " 389: 'particularly',\n",
              " 390: 'useful',\n",
              " 391: 'we',\n",
              " 392: 'finish',\n",
              " 393: 'add',\n",
              " 394: 'eggplant',\n",
              " 395: 'dates',\n",
              " 396: 'box',\n",
              " 397: 'professional',\n",
              " 398: 'teenagers',\n",
              " 399: 'hoot',\n",
              " 400: 'using',\n",
              " 401: 'contributing',\n",
              " 402: 'bulky',\n",
              " 403: 'dry',\n",
              " 404: 'steep',\n",
              " 405: 'swords',\n",
              " 406: 'love',\n",
              " 407: 'chalkboard',\n",
              " 408: 'hits',\n",
              " 409: 'against',\n",
              " 410: 'tensions',\n",
              " 411: 'spice',\n",
              " 412: 'horrified',\n",
              " 413: 'smack',\n",
              " 414: 'sundays',\n",
              " 415: 'perfection',\n",
              " 416: 'structure',\n",
              " 417: 'well',\n",
              " 418: 'clip',\n",
              " 419: 'hs850',\n",
              " 420: 'hide',\n",
              " 421: 'strap',\n",
              " 422: 'patio',\n",
              " 423: 'filmed',\n",
              " 424: 'means',\n",
              " 425: 'although',\n",
              " 426: 'mickey',\n",
              " 427: 'bohemian',\n",
              " 428: 'outperform',\n",
              " 429: 'rough',\n",
              " 430: 'recognition',\n",
              " 431: 'recieve',\n",
              " 432: 'nothingi',\n",
              " 433: 'n',\n",
              " 434: 'be',\n",
              " 435: 'cole',\n",
              " 436: 'containers',\n",
              " 437: 'brings',\n",
              " 438: 'bonus',\n",
              " 439: 'courteous',\n",
              " 440: 'heartwarming',\n",
              " 441: 'general',\n",
              " 442: 'paced',\n",
              " 443: 'fabulous',\n",
              " 444: 'detachable',\n",
              " 445: 'fits',\n",
              " 446: 'summer',\n",
              " 447: 'zombie',\n",
              " 448: 'soundwise',\n",
              " 449: '1010',\n",
              " 450: 'clearer',\n",
              " 451: 'howeverthe',\n",
              " 452: 'dinner',\n",
              " 453: 'tedium',\n",
              " 454: 'missing',\n",
              " 455: 'vinegrette',\n",
              " 456: 'commands',\n",
              " 457: 'garden',\n",
              " 458: 'accessing',\n",
              " 459: 'times',\n",
              " 460: 'ups',\n",
              " 461: 'teacher',\n",
              " 462: 'songs',\n",
              " 463: 'cool',\n",
              " 464: 'wants',\n",
              " 465: 'spiffy',\n",
              " 466: 'images',\n",
              " 467: 'user',\n",
              " 468: 'suspension',\n",
              " 469: 'fella',\n",
              " 470: 'smashburger',\n",
              " 471: 'fantasy',\n",
              " 472: 'ordered',\n",
              " 473: 'grilled',\n",
              " 474: 'shocked',\n",
              " 475: 'ages',\n",
              " 476: 'am',\n",
              " 477: 'plane',\n",
              " 478: 'spoiler',\n",
              " 479: 'plethora',\n",
              " 480: 'says',\n",
              " 481: 'lowkey',\n",
              " 482: 'endall',\n",
              " 483: 'producer',\n",
              " 484: 'samsung',\n",
              " 485: 'theft',\n",
              " 486: 'dropped',\n",
              " 487: 'dinners',\n",
              " 488: 'portable',\n",
              " 489: 'turkey',\n",
              " 490: 'listed',\n",
              " 491: 'gratuity',\n",
              " 492: '4s',\n",
              " 493: 'warning',\n",
              " 494: 'repertory',\n",
              " 495: 'portraying',\n",
              " 496: 'cow',\n",
              " 497: 'melodrama',\n",
              " 498: 'quinn',\n",
              " 499: 'backed',\n",
              " 500: 'opposed',\n",
              " 501: 'situations',\n",
              " 502: 'delights',\n",
              " 503: 'whiny',\n",
              " 504: 'wellit',\n",
              " 505: 'unmitigated',\n",
              " 506: 'welldesigned',\n",
              " 507: 'chodorov',\n",
              " 508: 'eighth',\n",
              " 509: 'event',\n",
              " 510: 'razor',\n",
              " 511: 'treated',\n",
              " 512: 'sunday',\n",
              " 513: 'live',\n",
              " 514: 'reservation',\n",
              " 515: 'endlessly',\n",
              " 516: 'age',\n",
              " 517: 'blandest',\n",
              " 518: 'need',\n",
              " 519: 'mistakes',\n",
              " 520: 'tigerlilly',\n",
              " 521: 'quantity',\n",
              " 522: 'ache',\n",
              " 523: 'complaints',\n",
              " 524: 'omg',\n",
              " 525: 'author',\n",
              " 526: 'available',\n",
              " 527: 'cameo',\n",
              " 528: 'key',\n",
              " 529: 'worry',\n",
              " 530: 'annes',\n",
              " 531: 'everyones',\n",
              " 532: 'damage',\n",
              " 533: 'deuchebaggery',\n",
              " 534: 'smith',\n",
              " 535: 'dancing',\n",
              " 536: 'tolerable',\n",
              " 537: '1995',\n",
              " 538: 'descriptions',\n",
              " 539: 'occur',\n",
              " 540: 'prime',\n",
              " 541: 'batch',\n",
              " 542: 'rude',\n",
              " 543: 'twist',\n",
              " 544: 'guacamole',\n",
              " 545: 'enjoyable',\n",
              " 546: 'definitely',\n",
              " 547: 'walkman',\n",
              " 548: 'geeky',\n",
              " 549: 'slowly',\n",
              " 550: 'gently',\n",
              " 551: 'surroundings',\n",
              " 552: 'waitresses',\n",
              " 553: 'mic',\n",
              " 554: 'joy',\n",
              " 555: 'scene',\n",
              " 556: 'generic',\n",
              " 557: 'enough',\n",
              " 558: 'palm',\n",
              " 559: 'stowe',\n",
              " 560: 'haggis',\n",
              " 561: 'slow',\n",
              " 562: 'towers',\n",
              " 563: '1979',\n",
              " 564: 'inch',\n",
              " 565: 'lightweight',\n",
              " 566: 'colleague',\n",
              " 567: 'jawbone',\n",
              " 568: 'rudely',\n",
              " 569: 'unrestrained',\n",
              " 570: 'decidely',\n",
              " 571: 'riot',\n",
              " 572: 'extensive',\n",
              " 573: 'pneumatic',\n",
              " 574: 'sorely',\n",
              " 575: 'hernandez',\n",
              " 576: 'gooodd',\n",
              " 577: 'drains',\n",
              " 578: 'humor',\n",
              " 579: 'noteworthy',\n",
              " 580: 'format',\n",
              " 581: 'knightley',\n",
              " 582: 'oil',\n",
              " 583: 'bully',\n",
              " 584: 'cheesecurds',\n",
              " 585: 'offensive',\n",
              " 586: 'appetizer',\n",
              " 587: 'lg',\n",
              " 588: 'zombiestudents',\n",
              " 589: 'tmobile',\n",
              " 590: 'describing',\n",
              " 591: 'disrespected',\n",
              " 592: 'chick',\n",
              " 593: 'goldencrispy',\n",
              " 594: 'production',\n",
              " 595: 'meeverything',\n",
              " 596: 'happiness',\n",
              " 597: 'undertone',\n",
              " 598: 'pull',\n",
              " 599: 'depicts',\n",
              " 600: 'bills',\n",
              " 601: 'ipod',\n",
              " 602: 'bussell',\n",
              " 603: 'beat',\n",
              " 604: 'flavorless',\n",
              " 605: 'regarding',\n",
              " 606: 'roeg',\n",
              " 607: 'firstperson',\n",
              " 608: 'gross',\n",
              " 609: 'asleep',\n",
              " 610: 'earbugs',\n",
              " 611: 'forget',\n",
              " 612: 'gentletouch',\n",
              " 613: 'fisted',\n",
              " 614: 'considering',\n",
              " 615: 'presents',\n",
              " 616: 'drift',\n",
              " 617: 'portions',\n",
              " 618: 'meats',\n",
              " 619: 'important',\n",
              " 620: 'elegantly',\n",
              " 621: 'chemistry',\n",
              " 622: 'places',\n",
              " 623: 'experiencing',\n",
              " 624: 'update',\n",
              " 625: 'money',\n",
              " 626: 'via',\n",
              " 627: 'di',\n",
              " 628: 'follow',\n",
              " 629: 'stand',\n",
              " 630: 'crab',\n",
              " 631: 'disturbing',\n",
              " 632: 'operas',\n",
              " 633: 'acceptable',\n",
              " 634: 'increase',\n",
              " 635: 'trythe',\n",
              " 636: 'cover',\n",
              " 637: 'jaclyn',\n",
              " 638: 'potted',\n",
              " 639: 'trond',\n",
              " 640: 'ethic',\n",
              " 641: 'tons',\n",
              " 642: 'upgrading',\n",
              " 643: 'goremeister',\n",
              " 644: 'tracfone',\n",
              " 645: 'az',\n",
              " 646: 'fast',\n",
              " 647: 'good7',\n",
              " 648: 'buffets',\n",
              " 649: 'belmondo',\n",
              " 650: 'stops',\n",
              " 651: 'sucks',\n",
              " 652: 'eaten',\n",
              " 653: 'ben',\n",
              " 654: 'lives',\n",
              " 655: 'taped',\n",
              " 656: 'mountain',\n",
              " 657: 'g',\n",
              " 658: 'v3c',\n",
              " 659: 'godfathers',\n",
              " 660: 'court',\n",
              " 661: 'poignant',\n",
              " 662: 'lewis',\n",
              " 663: 'factor',\n",
              " 664: 'wind',\n",
              " 665: 'bennett',\n",
              " 666: 'boyle',\n",
              " 667: 'lino',\n",
              " 668: 'themeat',\n",
              " 669: 'her',\n",
              " 670: 'year',\n",
              " 671: 'week',\n",
              " 672: 'loudly',\n",
              " 673: 'pulling',\n",
              " 674: 'owls',\n",
              " 675: 'vegas',\n",
              " 676: 'irritating',\n",
              " 677: 'unless',\n",
              " 678: 'stanwycks',\n",
              " 679: 'resolution',\n",
              " 680: 'loosely',\n",
              " 681: 'stereotypically',\n",
              " 682: 'mst3k',\n",
              " 683: 'paul',\n",
              " 684: 'serve',\n",
              " 685: 'identify',\n",
              " 686: 'ring',\n",
              " 687: 'messes',\n",
              " 688: 'tooth',\n",
              " 689: 'heat',\n",
              " 690: 'shifting',\n",
              " 691: 'fascinated',\n",
              " 692: 'offered',\n",
              " 693: 'development',\n",
              " 694: 'jason',\n",
              " 695: 'marrow',\n",
              " 696: 'undercooked',\n",
              " 697: 'outta',\n",
              " 698: 'anywhere',\n",
              " 699: 'walls',\n",
              " 700: 'flawlessly',\n",
              " 701: 'continually',\n",
              " 702: 'bouchon',\n",
              " 703: 'stale',\n",
              " 704: 'mechanism',\n",
              " 705: 'throwback',\n",
              " 706: 'yelpers',\n",
              " 707: 'proceedings',\n",
              " 708: 'rave',\n",
              " 709: 'point',\n",
              " 710: 'performing',\n",
              " 711: 'slideshow',\n",
              " 712: 'negligent',\n",
              " 713: 'attached',\n",
              " 714: 'latte',\n",
              " 715: 'former',\n",
              " 716: 'th',\n",
              " 717: 'rich',\n",
              " 718: 'himself',\n",
              " 719: 'media',\n",
              " 720: 'lose',\n",
              " 721: 'actions',\n",
              " 722: 'storm',\n",
              " 723: 'goes',\n",
              " 724: 'sucker',\n",
              " 725: 'crawl',\n",
              " 726: 'culture',\n",
              " 727: 'blue',\n",
              " 728: 'wedding',\n",
              " 729: 'outstanding',\n",
              " 730: 'levels',\n",
              " 731: 'loyalty',\n",
              " 732: '90s',\n",
              " 733: 'masculine',\n",
              " 734: 'nun',\n",
              " 735: 'roosevelts',\n",
              " 736: 'excuses',\n",
              " 737: 'autoanswer',\n",
              " 738: 'noted',\n",
              " 739: 'holes',\n",
              " 740: 'bellagio',\n",
              " 741: 'decay',\n",
              " 742: 'bacon',\n",
              " 743: 'skilled',\n",
              " 744: 'scared',\n",
              " 745: 'want',\n",
              " 746: 'debut',\n",
              " 747: 'onethis',\n",
              " 748: 'youre',\n",
              " 749: 'dickens',\n",
              " 750: '11',\n",
              " 751: 'something',\n",
              " 752: 'fair',\n",
              " 753: 'failed',\n",
              " 754: 'confirm',\n",
              " 755: 'fried',\n",
              " 756: 'billy',\n",
              " 757: 'performed',\n",
              " 758: 'completely',\n",
              " 759: 'any',\n",
              " 760: 'polite',\n",
              " 761: 'much',\n",
              " 762: 'angel',\n",
              " 763: 'letdown',\n",
              " 764: 'derivative',\n",
              " 765: 'luke',\n",
              " 766: 'wall',\n",
              " 767: 'homemade',\n",
              " 768: 'bug',\n",
              " 769: '785',\n",
              " 770: 'nimoy',\n",
              " 771: 'following',\n",
              " 772: 'ideal',\n",
              " 773: 'difference',\n",
              " 774: 'loudglad',\n",
              " 775: 'qwerty',\n",
              " 776: 'vegasthere',\n",
              " 777: '70000',\n",
              " 778: 'worldweariness',\n",
              " 779: 'rescue',\n",
              " 780: 'surely',\n",
              " 781: 'meals',\n",
              " 782: 'return',\n",
              " 783: 'company',\n",
              " 784: 'seafood',\n",
              " 785: 'roles',\n",
              " 786: 'miniseries',\n",
              " 787: 'hair',\n",
              " 788: 'reliability',\n",
              " 789: 'brilliant',\n",
              " 790: 'robert',\n",
              " 791: 'wit',\n",
              " 792: 'jabra350',\n",
              " 793: 'squibs',\n",
              " 794: 'lowbudget',\n",
              " 795: 'considered',\n",
              " 796: 'raspberry',\n",
              " 797: 'meet',\n",
              " 798: 'keys',\n",
              " 799: 'tempi',\n",
              " 800: 'cancan',\n",
              " 801: 'establish',\n",
              " 802: 'connoisseur',\n",
              " 803: 'max',\n",
              " 804: 'touching',\n",
              " 805: 'batter',\n",
              " 806: 'penny',\n",
              " 807: 'premium',\n",
              " 808: 'agree',\n",
              " 809: 'temperaments',\n",
              " 810: 'occasional',\n",
              " 811: 'irons',\n",
              " 812: 'crap',\n",
              " 813: 'café',\n",
              " 814: 'process',\n",
              " 815: 'give',\n",
              " 816: 'thorsen',\n",
              " 817: 'sharp',\n",
              " 818: 'gain',\n",
              " 819: 'pizza',\n",
              " 820: 'greatest',\n",
              " 821: 'voyage',\n",
              " 822: 'peach',\n",
              " 823: 'take',\n",
              " 824: 'witnessed',\n",
              " 825: 'soups',\n",
              " 826: 'directtovideo',\n",
              " 827: 'greatespecially',\n",
              " 828: 'breeders',\n",
              " 829: 'chocolate',\n",
              " 830: 'three',\n",
              " 831: 'detailed',\n",
              " 832: 'handy',\n",
              " 833: 'psychological',\n",
              " 834: 'closed',\n",
              " 835: 'lots',\n",
              " 836: 'garbled',\n",
              " 837: 'ians',\n",
              " 838: 'slimy',\n",
              " 839: 'dumb',\n",
              " 840: 'transmitters',\n",
              " 841: 'both',\n",
              " 842: 'ourselves',\n",
              " 843: 'pad',\n",
              " 844: 'cbr',\n",
              " 845: 'plastic',\n",
              " 846: 'chilly',\n",
              " 847: 'tribute',\n",
              " 848: 'pricing',\n",
              " 849: 'warn',\n",
              " 850: 'hat',\n",
              " 851: 'atrocious',\n",
              " 852: 'admins',\n",
              " 853: 'mesmerising',\n",
              " 854: 'angus',\n",
              " 855: 'heard',\n",
              " 856: 'thank',\n",
              " 857: 'abroad',\n",
              " 858: 'tear',\n",
              " 859: 'ms',\n",
              " 860: 'soundtrack',\n",
              " 861: 'cg',\n",
              " 862: 'smoothies',\n",
              " 863: 'multigrain',\n",
              " 864: 'operates',\n",
              " 865: 'no',\n",
              " 866: 'meal',\n",
              " 867: 'rendition',\n",
              " 868: 'twirling',\n",
              " 869: 'patron',\n",
              " 870: 'outgoing',\n",
              " 871: 'loved',\n",
              " 872: 'master',\n",
              " 873: 'shortlist',\n",
              " 874: 'war',\n",
              " 875: 'state',\n",
              " 876: 'excellentangel',\n",
              " 877: 'frustration',\n",
              " 878: 'sore',\n",
              " 879: 'e2',\n",
              " 880: 'freedom',\n",
              " 881: 'patty',\n",
              " 882: 'compelling',\n",
              " 883: 'treachery',\n",
              " 884: 'valentine',\n",
              " 885: 'crepe',\n",
              " 886: 'untoasted',\n",
              " 887: 'younger',\n",
              " 888: 'william',\n",
              " 889: 'petty',\n",
              " 890: 'thick',\n",
              " 891: 'cgi',\n",
              " 892: 'krussel',\n",
              " 893: 'ever',\n",
              " 894: 'groups',\n",
              " 895: 'appetite',\n",
              " 896: 'linking',\n",
              " 897: 'despicable',\n",
              " 898: 'inside',\n",
              " 899: 'searched',\n",
              " 900: 'concrete',\n",
              " 901: 'pans',\n",
              " 902: 'clothes',\n",
              " 903: 'screenplay',\n",
              " 904: 'practical',\n",
              " 905: 'acclaimed',\n",
              " 906: 'array',\n",
              " 907: 'overpriced',\n",
              " 908: 'premise',\n",
              " 909: 'channel',\n",
              " 910: 'baaaaaad',\n",
              " 911: 'cailles',\n",
              " 912: 'consider',\n",
              " 913: 'primal',\n",
              " 914: 'tungsten',\n",
              " 915: 'incorrectness',\n",
              " 916: 'stuff',\n",
              " 917: 'fish',\n",
              " 918: 'mediocre',\n",
              " 919: 'confuses',\n",
              " 920: 'puréed',\n",
              " 921: 'political',\n",
              " 922: 'calligraphy',\n",
              " 923: 'dream',\n",
              " 924: 'receives',\n",
              " 925: 'chinese',\n",
              " 926: 'depending',\n",
              " 927: 'feet',\n",
              " 928: 'voice',\n",
              " 929: 'painful',\n",
              " 930: 'kevin',\n",
              " 931: 'pm',\n",
              " 932: 'current',\n",
              " 933: 'soap',\n",
              " 934: 'unpredictable',\n",
              " 935: 'boasts',\n",
              " 936: 'voltage',\n",
              " 937: 'wallet',\n",
              " 938: 'abound',\n",
              " 939: 'doing',\n",
              " 940: 'pulled',\n",
              " 941: 'regret',\n",
              " 942: 'onion',\n",
              " 943: 'functional',\n",
              " 944: 'ball',\n",
              " 945: 'thrilled',\n",
              " 946: 'dosent',\n",
              " 947: 'dangerous',\n",
              " 948: 'theme',\n",
              " 949: 'semi',\n",
              " 950: 'contstruct',\n",
              " 951: 'try',\n",
              " 952: 'face',\n",
              " 953: 'connect',\n",
              " 954: 'surprise',\n",
              " 955: 'step',\n",
              " 956: 'ergonomic',\n",
              " 957: 'save',\n",
              " 958: 'mmmm',\n",
              " 959: 'miserable',\n",
              " 960: 'mood',\n",
              " 961: 'bed',\n",
              " 962: 'theatre',\n",
              " 963: 'belly',\n",
              " 964: 'companions',\n",
              " 965: 'women',\n",
              " 966: 'crackedi',\n",
              " 967: 'witty',\n",
              " 968: 'imaginative',\n",
              " 969: 'shots',\n",
              " 970: 'mac',\n",
              " 971: 'ghibili',\n",
              " 972: 'crispy',\n",
              " 973: 'nonfancy',\n",
              " 974: 'managementoh',\n",
              " 975: 'lap',\n",
              " 976: 'pedestal',\n",
              " 977: 'negulesco',\n",
              " 978: '30s',\n",
              " 979: 'wrap',\n",
              " 980: 'now',\n",
              " 981: 'significant',\n",
              " 982: 'win',\n",
              " 983: 'shine',\n",
              " 984: 'unreal',\n",
              " 985: 'lie',\n",
              " 986: 'junk',\n",
              " 987: 'may',\n",
              " 988: 'fly',\n",
              " 989: 'football',\n",
              " 990: 'special',\n",
              " 991: 'so',\n",
              " 992: '70s',\n",
              " 993: 'sisters',\n",
              " 994: 'cramming',\n",
              " 995: 'veganveggie',\n",
              " 996: 'ample',\n",
              " 997: 'evidently',\n",
              " 998: 'buldogis',\n",
              " 999: 'reading',\n",
              " 1000: 'tastings',\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cbMGMKDUdBS"
      },
      "source": [
        "with open('word_to_int_dict.json', 'w') as fp:\n",
        "  json.dump(word_to_int_dict, fp)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cshroNcMVBxh",
        "outputId": "4ed2bc9e-d869-49cd-fbd2-ff94195c1c4e"
      },
      "source": [
        "print(np.max([len(x) for x in reviews]))\n",
        "print(np.mean([len(x) for x in reviews]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70\n",
            "11.783666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFT5A2tKVwiQ"
      },
      "source": [
        "def pad_text(tokenized_reviews, seq_length):\n",
        "    \n",
        "    reviews = []\n",
        "    \n",
        "    for review in tokenized_reviews:\n",
        "        if len(review) >= seq_length:\n",
        "            reviews.append(review[:seq_length])\n",
        "        else:\n",
        "            reviews.append(['']*(seq_length-len(review)) + review)\n",
        "        \n",
        "    return np.array(reviews)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjUZ7wBYX2ev",
        "outputId": "4334d401-2400-454f-e6f3-1c8f43e78aed"
      },
      "source": [
        "padded_sentences = pad_text(reviews, seq_length = 50)\n",
        "\n",
        "padded_sentences[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
              "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
              "       '', '', '', '', '', '', '', 'very', 'cheap', 'plastic', 'creaks',\n",
              "       'like', 'an', 'old', 'wooden', 'floor'], dtype='<U33')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUpZdbEnYBuM"
      },
      "source": [
        "int_to_word_dict[0] = ''\n",
        "word_to_int_dict[''] = 0"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN1xTnk4bvBq",
        "outputId": "76e40510-3510-49da-9374-b155b060b5b9"
      },
      "source": [
        "encoded_sentences = np.array([[word_to_int_dict[word] for word in review] for review in padded_sentences])\n",
        "\n",
        "encoded_sentences[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0, 2536, 4406,  845,\n",
              "       4776, 2242, 1506, 3139, 2961, 1346])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXIO9jbzcd31"
      },
      "source": [
        "class SentimentLSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_vocab, n_embed, n_hidden, n_output, n_layers, drop_p = 0.8):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.n_vocab = n_vocab  \n",
        "        self.n_layers = n_layers \n",
        "        self.n_hidden = n_hidden \n",
        "        \n",
        "        self.embedding = nn.Embedding(n_vocab, n_embed)\n",
        "        self.lstm = nn.LSTM(n_embed, n_hidden, n_layers, batch_first = True, dropout = drop_p)\n",
        "        self.dropout = nn.Dropout(drop_p)\n",
        "        self.fc = nn.Linear(n_hidden, n_output)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "    def forward (self, input_words):\n",
        "                          \n",
        "        embedded_words = self.embedding(input_words)\n",
        "        lstm_out, h = self.lstm(embedded_words) \n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.n_hidden)\n",
        "        fc_out = self.fc(lstm_out)                  \n",
        "        sigmoid_out = self.sigmoid(fc_out)              \n",
        "        sigmoid_out = sigmoid_out.view(batch_size, -1)  \n",
        "        \n",
        "        sigmoid_last = sigmoid_out[:, -1]\n",
        "        \n",
        "        return sigmoid_last, h\n",
        "    \n",
        "    \n",
        "    def init_hidden (self, batch_size):\n",
        "        \n",
        "        device = \"cpu\"\n",
        "        weights = next(self.parameters()).data\n",
        "        h = (weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\n",
        "             weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n",
        "        \n",
        "        return h"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxEf9gTGe_Fk"
      },
      "source": [
        "n_vocab = len(word_to_int_dict)\n",
        "n_embed = 50\n",
        "n_hidden = 100\n",
        "n_output = 1\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentLSTM(n_vocab, n_embed, n_hidden, n_output, n_layers)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7YI03fMkbD5"
      },
      "source": [
        "labels = np.array([int(x) for x in data['Sentiment'].values])\n",
        "\n",
        "train_ratio = 0.8\n",
        "valid_ratio = (1 - train_ratio)/2\n",
        "\n",
        "total = len(encoded_sentences)\n",
        "train_cutoff = int(total * train_ratio)\n",
        "valid_cutoff = int(total * (1 - valid_ratio))\n",
        "\n",
        "train_x, train_y = torch.Tensor(encoded_sentences[:train_cutoff]).long(), torch.Tensor(labels[:train_cutoff]).long()\n",
        "valid_x, valid_y = torch.Tensor(encoded_sentences[train_cutoff : valid_cutoff]).long(), torch.Tensor(labels[train_cutoff : valid_cutoff]).long()\n",
        "test_x, test_y = torch.Tensor(encoded_sentences[valid_cutoff:]).long(), torch.Tensor(labels[valid_cutoff:])\n",
        "\n",
        "train_data = TensorDataset(train_x, train_y)\n",
        "valid_data = TensorDataset(valid_x, valid_y)\n",
        "test_data = TensorDataset(test_x, test_y)\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpiPHw_DooFl"
      },
      "source": [
        "print_every = 2400\n",
        "step = 0\n",
        "n_epochs = 3\n",
        "clip = 5\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EihoUvhCsfdF",
        "outputId": "3b56c950-6dbb-410e-8ee0-b51a1165ab55"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "  h = net.init_hidden(batch_size)\n",
        "\n",
        "  for inputs, labels in train_loader:\n",
        "    step = step + 1\n",
        "    net.zero_grad()\n",
        "    output, h = net(inputs)\n",
        "    loss = criterion(output.squeeze(), labels.float())\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm(net.parameters(), clip)\n",
        "    optimizer.step()\n",
        "\n",
        "    if (step % print_every) == 0:\n",
        "      net.eval()\n",
        "      valid_losses = []\n",
        "\n",
        "      for v_inputs, v_labels in valid_loader:\n",
        "\n",
        "        v_output, v_h = net(v_inputs)\n",
        "        v_loss = criterion(v_output.squeeze(), v_labels.float())\n",
        "        valid_losses.append(v_loss.item())\n",
        "\n",
        "\n",
        "      print(\"Epoch: {}/{}\".format((epoch+1), n_epochs),\n",
        "            \"Step: {}\".format(step),\n",
        "            \"Training Loss: {:.4f}\".format(loss.item()),\n",
        "            \"Validation Loss: {:.4f}\".format(np.mean(valid_losses)))\n",
        "      net.train()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/3 Step: 2400 Training Loss: 0.4108 Validation Loss: 0.6099\n",
            "Epoch: 2/3 Step: 4800 Training Loss: 2.3610 Validation Loss: 0.5489\n",
            "Epoch: 3/3 Step: 7200 Training Loss: 0.0244 Validation Loss: 0.6919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tFQOAgnv25K"
      },
      "source": [
        "torch.save(net.state_dict(), 'model.pkl')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4INyuNAo1htI"
      },
      "source": [
        "net = SentimentLSTM(n_vocab, n_embed, n_hidden, n_output, n_layers)\n",
        "net.load_state_dict(torch.load('model.pkl'))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w8g6niM2aUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "715371eb-d121-46c7-c858-30977748a3f8"
      },
      "source": [
        "net.eval()\n",
        "test_losses = []\n",
        "num_correct = 0\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "  test_output, test_h = net(inputs)\n",
        "  loss = criterion(test_output, labels)\n",
        "  test_losses.append(loss.item())\n",
        "\n",
        "  preds = torch.round(test_output.squeeze())\n",
        "  correct_tensor = preds.eq(labels.float().view_as(preds))\n",
        "  correct = np.squeeze(correct_tensor.numpy())\n",
        "  num_correct = num_correct + np.sum(correct)\n",
        "\n",
        "print(\"Test Loss: {:.4f}\".format(np.mean(test_losses)))\n",
        "print(\"Test Accuracy: {:.2f}\".format(num_correct/len(test_loader.dataset)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.7250\n",
            "Test Accuracy: 0.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASN_HoSDaDNb"
      },
      "source": [
        "def preprocess_review(review):\n",
        "  review = review.translate(str.maketrans('', '', punctuation)).lower().rstrip()\n",
        "  tokenized = word_tokenize(review)\n",
        "  if len(tokenized) >= 50:\n",
        "    review = tokenized[:50]\n",
        "  else:\n",
        "    review = ['0'] * (50-len(tokenized)) + tokenized\n",
        "\n",
        "  final = []\n",
        "\n",
        "  for token in review:\n",
        "    try:\n",
        "      final.append(word_to_int_dict[token])\n",
        "    except:\n",
        "      final.append(word_to_int_dict[''])\n",
        "\n",
        "    \n",
        "  return final"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1KLO7Qxbsnf"
      },
      "source": [
        "def predict(review):\n",
        "  net.eval()\n",
        "  words = np.array([preprocess_review(review)])\n",
        "  padded_words = torch.from_numpy(words)\n",
        "  pred_loader = DataLoader(padded_words, batch_size=1, shuffle=True)\n",
        "  for x in pred_loader:\n",
        "    output = net(x)[0].item()\n",
        "  \n",
        "  msg = \"This is a positive review.\" if output >= 0.5 else \"This is a negative review\"\n",
        "  print(msg)\n",
        "  print('Prediction = ' + str(output))\n",
        "  "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqXNIZWPcvSW",
        "outputId": "c92c468f-f9c9-49f9-a202-058d45c657f9"
      },
      "source": [
        "predict(\"The film was good\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a positive review.\n",
            "Prediction = 0.989628791809082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPSH_ORwc0Tq",
        "outputId": "73e1c362-751c-4c1d-947e-919dbc084d4d"
      },
      "source": [
        "predict(\"It was not good\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a negative review\n",
            "Prediction = 0.008618216030299664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CITwvzQldAl6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}